#! /bin/bash
# Specify strip_unit, 4k, 64k or 256k as parameter 1, default is 4K

debug=""
cephcmd="ceph"
rbdcmd="rbd"

typeset -i k=6

typeset -i drivesize=210000 #in megabytes
typeset -i fillpc=50
typeset -i numvols=6

# Working out the volume size based on
#(  Number of K drives * drive size ) /numvols 

typeset -i a=$drivesize*$k
typeset -i b=$a*$fillpc/100
typeset -i volsize=$b/$numvols

# need to recalculate the number of PGs with this page if 
# the number of OSDs changes:
# https://docs.ceph.com/en/squid/rados/operations/placement-groups/#placement-groups

echo "volsize = $volsize"

$debug $cephcmd config set mgr mgr/cephadm/use_repo_digest false
$debug $cephcmd orch apply osd --all-available-devices
# $debug $cephcmd config set global mon_allow_pool_size_one true

$debug $cephcmd osd pool create rbd_replicated replicated
# $debug $cephcmd osd pool set rbd_replicated size 1 --yes-i-really-mean-it
# $debug $cephcmd osd pool set rbd replicated_size min_size 1

$debug $cephcmd osd pool application enable rbd_replicated rbd

$debug $rbdcmd pool init rbd_replicated

hostname=$(hostname -f)
typeset -i endvol=$numvols-1

for i in $(seq 0 $endvol) 
do
   volname="cbt-librbdfio-${hostname}-${i}"
   $debug $rbdcmd create --pool rbd_replicated --size $volsize $volname 
done

# Check PG autoscaler progress, make sure all are in Complete or Not In Progress state
echo "Check PG autoscaler progress, make sure all are in Complete or Not in Progress state"
$debug ceph progress

exit

